<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script class="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"yoursite.com","root":"/","scheme":"Gemini","version":"8.0.0-rc.4","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":false,"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":false,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}}};
  </script>

  <meta name="description" content="Learning note of 2021 Hung-yi Lee Machine Learning Course.">
<meta property="og:type" content="article">
<meta property="og:title" content="Machine Learning Course Note">
<meta property="og:url" content="http://yoursite.com/2021/06/23/Machine-Learning-Course-Note/index.html">
<meta property="og:site_name" content="Silence Jiang&#39;s Cite">
<meta property="og:description" content="Learning note of 2021 Hung-yi Lee Machine Learning Course.">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://wordstream-files-prod.s3.amazonaws.com/s3fs-public/styles/simple_image/public/images/machine-learning1.png?SnePeroHk5B9yZaLY7peFkULrfW8Gtaf&amp;itok=yjEJbEKD">
<meta property="og:image" content="https://i.loli.net/2021/06/23/5vVFz2KRG7rIny3.png">
<meta property="og:image" content="https://i.loli.net/2021/06/26/MSwKBUlqZ3hIjYA.png">
<meta property="og:image" content="https://i.loli.net/2021/06/26/IG1Lnh7UoTf98aB.png">
<meta property="og:image" content="https://i.loli.net/2021/06/26/28HCo634VscIPGu.png">
<meta property="og:image" content="https://i.loli.net/2021/06/23/o3AQOKPEci6wWHC.png">
<meta property="og:image" content="https://scikit-learn.org/stable/_images/grid_search_workflow.png">
<meta property="og:image" content="https://pic2.zhimg.com/80/v2-d3ccd01453f215cf3357192debd14489_1440w.png">
<meta property="og:image" content="https://pic3.zhimg.com/80/v2-083ca0bcd0749fd0f236a690b50442e6_1440w.png">
<meta property="og:image" content="https://pic4.zhimg.com/80/v2-eea2dcbfa49df9fb799ef8e6997260bf_1440w.jpg">
<meta property="og:image" content="https://pic4.zhimg.com/80/v2-752c1c91e1b4dbca1b64f59a7e026b9b_1440w.jpg">
<meta property="og:image" content="https://pic4.zhimg.com/80/v2-3cd76d3e0d8a20d87dfa586b56cc1ad3_1440w.jpg">
<meta property="og:image" content="https://i.loli.net/2021/07/06/irnvSUHRkme4c8J.png">
<meta property="og:image" content="https://pic1.zhimg.com/v2-1c76cb1a90526acd6c6f6f9c6d6c7420_1440w.jpg?source=172ae18b">
<meta property="og:image" content="https://i.loli.net/2021/05/18/1VFZxoh5P6EGjBN.png">
<meta property="og:image" content="https://pic2.zhimg.com/80/v2-74f7d2430ace69c9cd6b963eb58a5079_1440w.jpg">
<meta property="og:image" content="https://i.loli.net/2021/09/09/5JYszjdgB2KeZ6C.png">
<meta property="og:image" content="https://i.loli.net/2021/09/13/mNQtYjHu4GZWDqA.png">
<meta property="og:image" content="https://i.loli.net/2021/09/13/QO7XLte8mFHudhx.png">
<meta property="og:image" content="https://i.loli.net/2021/09/13/Qjwx3aMZNOGuysC.png">
<meta property="og:image" content="https://i.loli.net/2021/09/13/WzxwAjPsk8CdEqN.png">
<meta property="og:image" content="https://i.loli.net/2021/09/13/HY3qr2bROTk1m4L.png">
<meta property="og:image" content="https://i.loli.net/2021/09/13/XLaxfthuv1zUpsR.png">
<meta property="og:image" content="https://i.loli.net/2021/09/23/nwzyUVPOIuiCgNW.png">
<meta property="og:image" content="https://i.loli.net/2021/09/22/srSLnFR8ejh3xEZ.png">
<meta property="og:image" content="https://i.loli.net/2021/09/26/LTdKt569WPwsICS.png">
<meta property="og:image" content="https://i.loli.net/2021/09/26/HOf8FMW3zad7Rls.png">
<meta property="og:image" content="https://i.loli.net/2021/09/26/jlTisyeYgDR7zKX.png">
<meta property="og:image" content="https://pic1.zhimg.com/80/v2-06c9787f9cd9a71d92ce0bbeb871af60_1440w.jpg">
<meta property="og:image" content="https://i.loli.net/2021/09/26/LMkBrs8V5odmIeR.png">
<meta property="og:image" content="https://i.loli.net/2021/09/26/X2xyT9Kgl51uDkf.png">
<meta property="og:image" content="https://i.loli.net/2021/09/27/59KtQxDNSeaohrT.png">
<meta property="og:image" content="https://i.loli.net/2021/09/27/Jqp8LzmX5kIMPn3.png">
<meta property="og:image" content="https://i.loli.net/2021/09/29/BmkPpoScafVn7gl.png">
<meta property="og:image" content="https://i.loli.net/2021/09/29/53STDYZaBx2bANr.png">
<meta property="og:image" content="https://i.loli.net/2021/09/29/4nSB23WH9aJzAlX.png">
<meta property="og:image" content="https://i.loli.net/2021/05/18/cq1yjMaveILkTzd.png">
<meta property="og:image" content="https://i.loli.net/2021/05/18/WXJ4PCbVIctwEsS.png">
<meta property="article:published_time" content="2021-06-23T12:49:05.050Z">
<meta property="article:modified_time" content="2021-10-13T05:40:20.927Z">
<meta property="article:author" content="Silence Jiang">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://wordstream-files-prod.s3.amazonaws.com/s3fs-public/styles/simple_image/public/images/machine-learning1.png?SnePeroHk5B9yZaLY7peFkULrfW8Gtaf&amp;itok=yjEJbEKD">

<link rel="canonical" href="http://yoursite.com/2021/06/23/Machine-Learning-Course-Note/">


<script class="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>Machine Learning Course Note | Silence Jiang's Cite</title>
  






  <noscript>
  <style>
  body { margin-top: 2rem; }

  .use-motion .menu-item,
  .use-motion .sidebar,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header {
    visibility: visible;
  }

  .use-motion .header,
  .use-motion .site-brand-container .toggle,
  .use-motion .footer { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle,
  .use-motion .custom-logo-image {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line {
    transform: scaleX(1);
  }

  .search-pop-overlay, .sidebar-nav { display: none; }
  .sidebar-panel { display: block; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="Silence Jiang's Cite" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container">
    <div class="headband"></div>

    <main class="main">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader">
        <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
        <span class="toggle-line toggle-line-first"></span>
        <span class="toggle-line toggle-line-middle"></span>
        <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Silence Jiang's Cite</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-lover">

    <a href="/lover/" rel="section"><i class="fa fa-heart fa-fw"></i>lover</a>

  </li>
        <li class="menu-item menu-item-schedule">

    <a href="/schedule/" rel="section"><i class="fa fa-calendar fa-fw"></i>Schedule</a>

  </li>
  </ul>
</nav>




</div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <section class="post-toc-wrap sidebar-panel">
          <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Basic-Concepts"><span class="nav-number">1.</span> <span class="nav-text">Basic Concepts</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Classification"><span class="nav-number">2.</span> <span class="nav-text">Classification</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Logistic-Regression"><span class="nav-number">3.</span> <span class="nav-text">Logistic Regression</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Backpropagation"><span class="nav-number">4.</span> <span class="nav-text">Backpropagation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Support-Vector-Machine"><span class="nav-number">5.</span> <span class="nav-text">Support Vector Machine</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Deep-Learning"><span class="nav-number">6.</span> <span class="nav-text">Deep Learning</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Convolutional-Neural-Network"><span class="nav-number">7.</span> <span class="nav-text">Convolutional Neural Network</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Self-attention"><span class="nav-number">8.</span> <span class="nav-text">Self-attention</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Transformer"><span class="nav-number">9.</span> <span class="nav-text">Transformer</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Recurrent-Neural-Network"><span class="nav-number">10.</span> <span class="nav-text">Recurrent Neural Network</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Semi-supervised-Learning"><span class="nav-number">11.</span> <span class="nav-text">Semi-supervised Learning</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Unsupervised-Learning"><span class="nav-number">12.</span> <span class="nav-text">Unsupervised Learning</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Cluster"><span class="nav-number">12.1.</span> <span class="nav-text">Cluster</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#PCA"><span class="nav-number">12.2.</span> <span class="nav-text">PCA</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#SVD"><span class="nav-number">12.3.</span> <span class="nav-text">SVD</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Word-Embedding"><span class="nav-number">12.4.</span> <span class="nav-text">Word Embedding</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Self-supervised-Learning"><span class="nav-number">13.</span> <span class="nav-text">Self-supervised Learning</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Generative-Adversarial-Network-GAN"><span class="nav-number">13.1.</span> <span class="nav-text">Generative Adversarial Network (GAN)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Pre-train"><span class="nav-number">13.2.</span> <span class="nav-text">Pre-train</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Auto-encoder"><span class="nav-number">13.3.</span> <span class="nav-text">Auto-encoder</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Domain-Adaptation"><span class="nav-number">14.</span> <span class="nav-text">Domain Adaptation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Explainable-Machine-Learning"><span class="nav-number">15.</span> <span class="nav-text">Explainable Machine Learning</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Attack-ML-Model"><span class="nav-number">16.</span> <span class="nav-text">Attack ML Model</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Reinforcement-Learning"><span class="nav-number">17.</span> <span class="nav-text">Reinforcement Learning</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Life-Long-Learning"><span class="nav-number">18.</span> <span class="nav-text">Life Long Learning</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Network-Compression"><span class="nav-number">19.</span> <span class="nav-text">Network Compression</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Reference"><span class="nav-number">20.</span> <span class="nav-text">Reference</span></a></li></ol></div>
      </section>
      <!--/noindex-->

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Silence Jiang"
      src="https://i.loli.net/2021/06/24/DBH4z2SpijZrQ17.jpg">
  <p class="site-author-name" itemprop="name">Silence Jiang</p>
  <div class="site-description" itemprop="description">I'm right here waiting for you.</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
          <span class="site-state-item-count">12</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">12</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/SilenceX12138" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;SilenceX12138" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.instagram.com/silencejiang12138" title="Instagram → https:&#x2F;&#x2F;www.instagram.com&#x2F;silencejiang12138" rel="noopener" target="_blank"><i class="fab fa-instagram fa-fw"></i>Instagram</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://weibo.com/u/2214676725" title="Weibo → https:&#x2F;&#x2F;weibo.com&#x2F;u&#x2F;2214676725" rel="noopener" target="_blank"><i class="fab fa-weibo fa-fw"></i>Weibo</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:silencejiang12138@gmail.com" title="E-Mail → mailto:silencejiang12138@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </section>
    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </header>

      
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>

<noscript>
  <div id="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


      <div class="main-inner">
        

        <div class="content post posts-expand">
          

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2021/06/23/Machine-Learning-Course-Note/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="https://i.loli.net/2021/06/24/DBH4z2SpijZrQ17.jpg">
      <meta itemprop="name" content="Silence Jiang">
      <meta itemprop="description" content="I'm right here waiting for you.">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Silence Jiang's Cite">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Machine Learning Course Note
        </h1>

        <div class="post-meta">

          
            <i class="fas fa-thumbtack"></i>
            <font color=7D26CD>置顶</font>
            <span class="post-meta-divider">|</span>
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-06-23 20:49:05" itemprop="dateCreated datePublished" datetime="2021-06-23T20:49:05+08:00">2021-06-23</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2021-10-13 13:40:20" itemprop="dateModified" datetime="2021-10-13T13:40:20+08:00">2021-10-13</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/ML/" itemprop="url" rel="index"><span itemprop="name">ML</span></a>
                </span>
                  , 
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AI/" itemprop="url" rel="index"><span itemprop="name">AI</span></a>
                </span>
            </span>

          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine: </span>
    
    <a title="valine" href="/2021/06/23/Machine-Learning-Course-Note/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2021/06/23/Machine-Learning-Course-Note/" itemprop="commentCount"></span>
    </a>
  </span>
  
  <br>
            <span class="post-meta-item" title="Symbols count in article">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">Symbols count in article: </span>
              <span>19k</span>
            </span>
            <span class="post-meta-item" title="Reading time">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">Reading time &asymp;</span>
              <span>17 mins.</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p><strong>Learning note of 2021 Hung-yi Lee Machine Learning Course.</strong></p>
<p><img src="https://wordstream-files-prod.s3.amazonaws.com/s3fs-public/styles/simple_image/public/images/machine-learning1.png?SnePeroHk5B9yZaLY7peFkULrfW8Gtaf&amp;itok=yjEJbEKD" alt="10 Companies Using Machine Learning in Cool Ways | WordStream"></p>
<a id="more"></a>
<blockquote>
<p><strong>Course Project Code is available at: <a href="https://github.com/SilenceX12138/Cheetah" target="_blank" rel="noopener">https://github.com/SilenceX12138/Cheetah</a></strong></p>
</blockquote>
<h2 id="Basic-Concepts"><a href="#Basic-Concepts" class="headerlink" title="Basic Concepts"></a>Basic Concepts</h2><ul>
<li><p>当训练集loss小而测试集loss大时，<strong>不一定是</strong>过拟合，也有可能是因为训练集和测试集数据<strong>分布不同</strong>而造成的mismatch.</p>
</li>
<li><p>神经网络在训练时会有随机因素影响参数的更新，但是在训练结束后应当具有稳定的输出。</p>
</li>
<li><p>数据增强需要根据数据本身的特性进行，例如图像通常会进行左右翻转而<strong>不是</strong>上下翻转。</p>
</li>
<li><p>模型训练时遇到的梯度为0的点成为critical point，分为局部最小值、局部最大值和鞍点，其中<strong>鞍点最为常见</strong>。</p>
<blockquote>
<p>出现鞍点时，理论上可以通过计算Hessian矩阵的特征值，根据特征值为负的向量来更新参数，但实际操作时由于计算量较大而<strong>不采用</strong>。</p>
</blockquote>
</li>
<li><p><strong>最小化</strong>交叉熵等价于<strong>最大化</strong>似然函数</p>
<ul>
<li>交叉熵：衡量两个分布之间的差异</li>
<li>似然：模型对样本分布的解释力度</li>
</ul>
</li>
</ul>
<h2 id="Classification"><a href="#Classification" class="headerlink" title="Classification"></a>Classification</h2><ul>
<li><p>Naïve Bayes</p>
<ul>
<li><p>判别模型&amp;生成模型：<a href="https://www.zhihu.com/question/20446337/answer/256466823" target="_blank" rel="noopener">https://www.zhihu.com/question/20446337/answer/256466823</a></p>
<blockquote>
<ul>
<li>判别模型学习区别，生成模型学习本质。</li>
<li>判别模型直接对$P(C|x)$进行建模，而生成模型先求$P(C,x)$.</li>
<li>判别模型力求<strong>经验误差最小化</strong>，生成模型强调<strong>出现概率最大化</strong>。</li>
</ul>
</blockquote>
</li>
<li><p>“拉普拉斯修正”平滑操作可以避免信息被训练集中未出现的属性值“抹去”</p>
<blockquote>
<p>假设属性值与类别均匀分布</p>
</blockquote>
</li>
<li><p>联合概率：包含多个条件且<strong>所有条件同时成立</strong>的概率，记作$P(X=a,Y=b)$或$P(a,b)$.</p>
</li>
</ul>
</li>
<li><p>参数估计：设$p(x)=f(\theta)$即$x$的概率分布与$\theta$相关</p>
<ul>
<li><p>极大似然：$argmax\{P(x|\theta)\}$，取能够使概率值最大的参数$\theta$.</p>
<blockquote>
<p>$P(x|\theta)$实际上就是将$\theta$代入假设的分布后得到的函数</p>
</blockquote>
</li>
<li><p>贝叶斯：在$p(x)$分布的基础上，设出第二个参数的分布$g(\theta)$.通过贝叶斯公式估计$g(\theta)$，然后求出期望平均作为$\theta$的估计值，然后再求出$p(x)$</p>
</li>
<li><p>最大后验概率：$argmax\{P(x|\theta)P(\theta)\}$，即在极大似然的基础上增加对参数本身概率的考量。（$P(\theta)$是对数据的<strong>主观认识</strong>，即人为设置其概率分布）</p>
</li>
</ul>
</li>
<li><p>$\hat{y}$在李宏毅老师MOOC中表示<strong>真实值</strong>，而西瓜书中是<strong>预测值</strong>。</p>
</li>
</ul>
<h2 id="Logistic-Regression"><a href="#Logistic-Regression" class="headerlink" title="Logistic Regression"></a>Logistic Regression</h2><ul>
<li><p>Logistic Regression是在线性回归的基础上增加了<code>sigmoid</code>函数，解决的是<strong>分类问题</strong>。</p>
</li>
<li><p>偏置项用于增强模型的拟合能力：<a href="https://www.zhihu.com/question/305340182/answer/721739423" target="_blank" rel="noopener">https://www.zhihu.com/question/305340182/answer/721739423</a></p>
<blockquote>
<p>偏置也可以理解成<strong>阈值</strong>，只有当计算出的值足够大时（大过阈值），才表示决策更加笃定。</p>
</blockquote>
</li>
<li><p>Logistic Regression使用的误差表示方法是<strong>交叉熵</strong>，因为MSE会出现label处梯度为0的情况，不能保证优化参数。</p>
</li>
<li><p>$y=w^Tx+b$越大越好的原因：损失函数中想要使$f(y)$在正样本时尽量向<code>1</code>靠近，也就是要求$y$的值尽量大，所以$y$越大则表示样本分类为正的可能性越大。</p>
<blockquote>
<p>如果正样本时要求$f(y)$向<code>-1</code>靠近，则$y$的值就应该越小越好。</p>
</blockquote>
</li>
<li><p>通过多个Logistic Regressor的拼接，可以构成神经网络。</p>
<blockquote>
<ul>
<li>本质上是用Logistic Regression来寻找<strong>最好</strong>的特征</li>
<li>最后的输出层实际上是<code>OvR</code>模型</li>
</ul>
</blockquote>
</li>
<li><p>softmax的作用：将不同类别的预测值归一化，同时将差异<strong>放大</strong>。</p>
<p><img src="https://i.loli.net/2021/06/23/5vVFz2KRG7rIny3.png" alt="img" style="zoom: 50%;" /></p>
<blockquote>
<p>同时将<strong>负</strong>预测值转换为<strong>正值</strong></p>
</blockquote>
</li>
<li><p>梯度下降方法是<strong>提前</strong>将偏微分公式求出，然后带入实际的参数（权值、偏置）进行计算得到梯度值，然后更新参数，例子如下：$\left(x_{2}\right)=\left(x_{1}\right)-\eta \nabla f\left(x_{1}\right)=(6)-0.2 \times(12)=(3.6)$​.</p>
</li>
<li><p>样本不平衡</p>
<ul>
<li>过采样：<strong>不能</strong>简单地对正样本进行复制，否则很容易造成过拟合。</li>
<li>欠采样：使用多个学习器将反例划分为若干个集合供训练使用</li>
<li>再缩放：根据$\frac{y}{1-y}&gt;\frac{m^+}{m^-}$来对正负样本进行判定​</li>
</ul>
</li>
</ul>
<h2 id="Backpropagation"><a href="#Backpropagation" class="headerlink" title="Backpropagation"></a>Backpropagation</h2><ul>
<li><p>反向传播是一种高效的计算<strong>损失函数</strong>相对于参数<strong>梯度</strong>的办法</p>
</li>
<li><p>参数更新方程：<script type="math/tex">\cases {w_i^2=w_i^1-\Delta w_i \\ \Delta w_i=\eta*\frac{\partial L}{\partial w_i}}</script></p>
<blockquote>
<ul>
<li>更新方向和梯度方向<strong>相反</strong></li>
<li>存在多种不同的更新方式（优化器）</li>
</ul>
</blockquote>
</li>
<li><p>$\frac{\partial C}{\partial w_n}=\frac{\partial C}{\partial z}*\frac{\partial z}{\partial w_n}$</p>
<ul>
<li>$C$(cost)是某一个样本的预测值和真实值的<strong>距离</strong></li>
<li>$z$是$w_n$对应神经元的输入值线性回归（<strong>没有</strong>经过激活函数）</li>
<li>损失函数是多个$C$的累加</li>
</ul>
</li>
<li><p>$\frac{\partial z}{\partial w_n}=x_n$：<code>Forward Pass</code>中，单层神经元的输出对<strong>权重</strong>求导是对应的<strong>输入特征</strong>的值。</p>
</li>
<li><p>$\frac{\partial C}{\partial z}$：<code>Backward Pass</code>本质上和正向的<code>Forward Pass</code>相同，即建立一个反向的神经网络进行正常的<strong>预测</strong>计算。</p>
<ul>
<li>反向网络中神经元的激活函数是原激活函数的<strong>导函数</strong></li>
<li>反向网络的激活函数直接和线性回归方程<strong>相乘</strong>，而<strong>不是复合</strong>。</li>
</ul>
</li>
<li><p><code>Sigmoid</code>函数可能导致梯度消失：<strong>输出端</strong>参数收敛，<strong>输入端</strong>参数依然处在随机态。</p>
</li>
<li><p>一个神经元 = 一组权值门 + 一个偏置值（ <strong>+ 一个激活函数</strong>） </p>
<p><img src="https://i.loli.net/2021/06/26/MSwKBUlqZ3hIjYA.png" alt="image-20210626204839498" style="zoom:33%;" /></p>
<blockquote>
<ul>
<li>可以没有激活函数，例如回归问题中最后的输出神经元。</li>
<li>激活函数是为了引入非线性因素，增强网络的表达能力。</li>
</ul>
</blockquote>
</li>
<li><p>反向传播中，每个神经元存储$\frac{\partial C}{\partial z}$即损失值对当前神经元输入值的微分，然后反向计算前一层神经元的$\frac{\partial C}{\partial z}$，最后与前一层网络权值对应的输入特征相乘即可得到$\frac{\partial C}{\partial w_n}$.</p>
<p><img src="https://i.loli.net/2021/06/26/IG1Lnh7UoTf98aB.png" alt="image-20210626205358640" style="zoom: 50%;" /></p>
<blockquote>
<p><strong>反向传播的起点</strong>：输出端的初始值$\frac{\partial C}{\partial y}$</p>
<p><img src="https://i.loli.net/2021/06/26/28HCo634VscIPGu.png" alt="image-20210626205609655" style="zoom:50%;" /></p>
</blockquote>
</li>
</ul>
<h2 id="Support-Vector-Machine"><a href="#Support-Vector-Machine" class="headerlink" title="Support Vector Machine"></a>Support Vector Machine</h2><ul>
<li><p>SVM对噪声敏感</p>
</li>
<li><p>硬间隔：$\hat{y}^if(x_i)\geq 1$</p>
</li>
<li><p>软间隔：</p>
<ul>
<li><p>目标函数：$min\ \frac{||w||_2}{2}+C\Sigma l(\hat{y}^if(x^i)-1)$</p>
<ul>
<li><p>$C$：常数，无穷大时<strong>不允许</strong>错误出现，软间隔变为硬间隔。</p>
</li>
<li><p>$l(x)$：<code>0/1</code>损失函数，当$x&lt;0$时，取值为1.通常使用<code>hinge loss</code>函数($l(z)=max\{0,1-z\}$)代替</p>
<blockquote>
<p><code>hinge loss</code>是$l(x)$的<strong>紧凑上界</strong></p>
</blockquote>
</li>
</ul>
</li>
<li><p>约束：$\hat{y}^if(x^i)\geq 1-\epsilon^i(\epsilon^i \geq 0)$</p>
</li>
<li>求解<ul>
<li>拉格朗日乘子法+SMO</li>
<li>线性SVM：<strong>梯度下降</strong>（间断函数如<code>hinge loss</code>也是可以使用梯度下降进行优化的）</li>
</ul>
</li>
</ul>
<blockquote>
<p>在使用<code>hinge loss</code>函数时，$\epsilon ^i=max\{0,1-\hat{y}^if(y^i)\}$，即满足非负约束和大于$1-\hat{y}^if(x^i)$的条件下，令$\Sigma \epsilon^i$尽量小，从而使目标函数最小。</p>
</blockquote>
</li>
<li><p>核函数</p>
<ul>
<li>让特征在高维空间<strong>线性可分</strong>，从而得到一个非线性SVM.（普通支持向量机<strong>只能解决线性可分</strong>问题，此时SVM可以处理低维空间线性不可分的数据）</li>
<li>降低运算量，在计算高维空间的目标函数时不需要真正做变换，只需要计算核函数即可。</li>
</ul>
</li>
<li><p>SVM/SVR学习出的模型都可以表示成<strong>核函数的线性组合</strong>：$h^*(x)=\Sigma\alpha_i K(x,x_i)$</p>
<ul>
<li>模型仅与支持向量有关，<strong>不用记录</strong>其他样本。</li>
<li>偏置项被合并进了支持向量</li>
</ul>
</li>
</ul>
<h2 id="Deep-Learning"><a href="#Deep-Learning" class="headerlink" title="Deep Learning"></a>Deep Learning</h2><ul>
<li><p>神经网络的作用：用于寻找一个能够优化目标的<strong>函数</strong>，即参数设置。</p>
<ul>
<li>神经网络可以拟合任意函数，因此<strong>不同的参数</strong>下神经网络所代表的<strong>函数不同</strong>。</li>
<li>以<code>WGAN</code>为例，$L_D=-E[D(x)]+E[D(\hat{x})]$​​.为了能够最小化该损失函数，需要寻找一个合适的$D$​​，而神经网络+梯度下降就能够通过调整参数（实际上是<strong>不停更换函数</strong>）确保找到一个<strong>相对最优解</strong>​，从而实现优化问题。</li>
<li>神经网络并<strong>不完全等于</strong>普通意义上的函数，因为其输出可以是一个值、一个分布甚至是一张图片。因此，只要能够找到对应的优化目标，例如MSE、交叉熵等，就能通过梯度下降方法找到一个理想的函数（一组神经网络参数）</li>
</ul>
</li>
<li><p>同样的参数量，深层神经网络比只有一层的感知机性能更好。因此，尽管普通全连接神经网络可以拟合任意函数，仍旧需要各种<strong>不同结构的模型</strong>解决<strong>不同场景下的问题</strong>。</p>
<ul>
<li>深层神经网络蕴含了“模块化”的思想，例如各层网络进行不同维度的分类。</li>
<li>因为每个模块的分类功能并不复杂，神经网络需要的训练数据实际上是<strong>更少</strong>的。</li>
</ul>
</li>
<li><p>End-to-end Learning：让流水线上每一个函数自己学习相应的特征</p>
</li>
<li><p>训练指南</p>
<ul>
<li><p>神经网络不收敛的常见原因</p>
<ul>
<li><p>样本不平衡</p>
<ul>
<li>解决办法：使用<code>WeightedRandomSampler</code></li>
</ul>
</li>
<li><p>优化器在每个batch都要梯度清零</p>
<ul>
<li><p>也可以通过模型自身清零</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">G.zero_grad()</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
</li>
<li><p>过拟合的<strong>前提</strong>是训练集的表现很好，如果训练集就没有高性能，那么不叫过拟合。</p>
</li>
<li><p>训练集</p>
<ul>
<li>更换激活函数<ul>
<li>ReLU函数可以<strong>防止</strong>梯度消失：有效的神经元是线性的，不会出现极小的梯度。</li>
</ul>
</li>
<li>调整学习率</li>
</ul>
</li>
<li><p>测试集</p>
<ul>
<li><p>及时停止训练：根据<strong>验证集</strong>确定时机</p>
<ul>
<li><p>验证集(fold 5)&amp;测试集</p>
<p><img src="https://i.loli.net/2021/06/23/o3AQOKPEci6wWHC.png" alt="img"></p>
<ul>
<li><p>验证集用于模型筛选、调优和消融实验</p>
</li>
<li><p>交叉验证是一种<strong>“不再单独划分验证集”</strong>的方式，即采用交叉验证则<strong>不需要</strong>再单独划分验证集，使用<strong>交叉验证评价指标的平均值</strong>即可衡量模型性能表现。但对于需要<code>early_stop</code>的模型，不能使用封装的<code>GridSearchCV</code>（无法显式获取当前轮次验证集），需要手动划分数据集后在fit时使用验证集作为<code>eval_set</code>。</p>
<blockquote>
<p>当数据量很大时，也可以<strong>并行使用</strong>交叉验证和单独的验证集。</p>
</blockquote>
<p><img src="https://scikit-learn.org/stable/_images/grid_search_workflow.png" alt="Grid Search Workflow" style="zoom: 25%;" /></p>
</li>
</ul>
</li>
</ul>
</li>
<li><p>测试集<strong>仅</strong>用于评估模型性能</p>
</li>
<li><p>正则化：正则项有多种形式，例如L1/L2.</p>
<blockquote>
<ul>
<li>正则项中通常<strong>不含</strong>偏置项</li>
<li>正则化目的是让参数尽量靠近零，某些情况下效果<strong>不如</strong>停止训练显著。</li>
</ul>
</blockquote>
</li>
<li><p>Dropout：在<strong>训练</strong>过程中<strong>每次</strong>更新参数时，以概率值$p$随机<strong>舍弃</strong>一些神经元。（激活函数以概率$p$输出0）</p>
<ul>
<li>rescale：预测时<strong>所有神经元</strong>都会参与，输出是朴素情况$\frac{1}{1-p}$倍，因此需要乘$(1-p)$保证规模正常。</li>
</ul>
</li>
<li><p>inverted dropout：在训练时将<strong>输出缩小</strong>为$(1-p)$，测试时就<strong>不需要</strong>rescale了。</p>
</li>
<li><p>Batch Normalization：在<strong>激励函数前</strong>对数据特征值进行标准化，可以提高模型和性能和学习速度。</p>
<p><img src="https://pic2.zhimg.com/80/v2-d3ccd01453f215cf3357192debd14489_1440w.png" alt="img" style="zoom:33%;" /></p>
<ul>
<li><p>在BN操作外还需要添加<strong>反标准化</strong>，从而使神经网络自行对BN有效性进行判断，即学习参数$\gamma$和$\beta$.</p>
<p><img src="https://pic3.zhimg.com/80/v2-083ca0bcd0749fd0f236a690b50442e6_1440w.png" alt="img" style="zoom:33%;" /></p>
</li>
<li><p>BN操作本质上是使<strong>error surface平滑</strong>，避免模型困在critical point.</p>
</li>
<li><p><code>BatchNorm</code>原理: <a href="https://blog.csdn.net/happynear/article/details/44238541" target="_blank" rel="noopener">https://blog.csdn.net/happynear/article/details/44238541</a></p>
</li>
<li><p><code>z-score</code><strong>不会</strong>改变分布本身的形状：<a href="https://www.zhihu.com/question/38102762" target="_blank" rel="noopener">https://www.zhihu.com/question/38102762</a></p>
</li>
<li><p>2维BN是在各个通道间<strong>独立</strong>进行的即在每一层对$N<em>H</em>W$个数值求均值和方差</p>
<blockquote>
<p><strong>不是</strong>仅在每个位置上求具体$C$像素个像素的均值和方差</p>
</blockquote>
</li>
<li><p>当对每一个样本单独进行正则化时，即通道之间<strong>相关</strong>，就可以得到Layer Normalization.</p>
<ul>
<li>LN对每个样本，即$C<em>H</em>W$计算均值和方差。</li>
<li>BN仅针对<strong>一组</strong>神经元（同通道），而LN针对<strong>一层</strong>神经元。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>SGD&amp;标准GD$\Leftrightarrow$​标准BP&amp;累计BP，即单个样本&amp;batch中的样本。</p>
</li>
<li><p>ROC和AUC计算：<a href="https://zhuanlan.zhihu.com/p/25212301" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/25212301</a></p>
</li>
</ul>
<h2 id="Convolutional-Neural-Network"><a href="#Convolutional-Neural-Network" class="headerlink" title="Convolutional Neural Network"></a>Convolutional Neural Network</h2><ul>
<li><p>卷积的作用</p>
<ul>
<li>特征的位置对特征的识别没有影响</li>
<li>特征可能只在原图中的很小一部分</li>
</ul>
</li>
<li><p>池化的作用</p>
<ul>
<li>缩放原图不影响特征的信息</li>
</ul>
</li>
<li><p>卷积的本质</p>
<ul>
<li>权重是卷积的<strong>参数</strong></li>
<li>全连接网络<strong>舍弃</strong>一部分权重</li>
<li>卷积层之后的神经元<strong>共享</strong>权重</li>
</ul>
</li>
<li><p>卷积核的叠加：10个1*3*3的卷积核将图像从1升维到10后，下一个卷积核实际上是<strong>三维</strong>的，即10*3*3.此时如果再将图像升维，则需要<strong>多个</strong>三维卷积核。</p>
</li>
<li><p>特征图中的<strong>一个像素</strong>实际上就是<strong>一个神经元</strong>（<strong>不包括</strong>激活函数）</p>
</li>
<li><p>一维卷积&amp;二维卷积&amp;三维卷积</p>
<blockquote>
<p>通道数是把<strong>一组</strong>神经元进行多次<strong>复制堆叠</strong>，而维度则是摊开变成<strong>一组</strong>神经元。（有时一层神经元也可指考虑维度后得到的多组神经元的集合）</p>
</blockquote>
<ul>
<li><p><code>conv1D</code>：可以具有多个通道，但是每个通道是<strong>一维</strong>的，其中通道又被称为<code>embedding</code>，例如自然语言处理。</p>
<ul>
<li><p>eg. $8<em>16$的数据表示$8$个单词（时间戳etc.）且每个单词有$16$个维度，此时滤波器（卷积核）大小为$8</em>K$，最终的结果依然只有<strong>一维</strong>。</p>
</li>
<li><p><strong>一维</strong>卷积的<strong>卷积核</strong>是<strong>二维</strong>的，每个通道是<strong>一维</strong>的。</p>
</li>
<li><p>PyTorch输入输出格式</p>
<ul>
<li><p>input: $(N, C_{\text{in}}, L)$​</p>
</li>
<li><p>output: $\left(N, C_{\text {out }}, L_{\text {out }}\right)$</p>
<p>$L_{o u t}=\lfloor\frac{L_{i n}+2 \times \text { padding }-\text { dilation } \times(\text { kernel_size }-1)-1}{\text { stride }}+1\rfloor$</p>
</li>
</ul>
</li>
</ul>
</li>
<li><p><code>conv2D</code>：可以具有多个通道，但是每个通道是<strong>二维</strong>的，例如图像处理。</p>
<ul>
<li>每个通道的卷积计算结果<strong>最后相加</strong>作为输出的结果，即$C<em>H</em>W$的图像经过$C<em>K</em>K$的卷积核扫描后产生$1<em>H’</em>W’$​​的结果，<strong>有几个卷积核则最终结果就有几个通道</strong>。</li>
<li><strong>二维</strong>卷积的<strong>卷积核</strong>是<strong>三维</strong>的，每个通道是<strong>二维</strong>的。</li>
<li>PyTorch输入输出格式<ul>
<li><strong>input:</strong> $\left(N, C_{\mathrm{in}}, H, W\right)$​</li>
<li><strong>output:</strong> $\left(N, C_{\text {out }}, H_{\text {out }}, W_{\text {out }}\right)$​</li>
</ul>
</li>
</ul>
</li>
<li><p><code>conv3D</code>：每个通道是<strong>三维</strong>的，例如CT影像和视频处理。</p>
<ul>
<li><strong>三维</strong>卷积的<strong>卷积核</strong>是<strong>四维</strong>的，每个通道是<strong>三维</strong>的。</li>
<li>PyTorch输入输出格式：<ul>
<li><strong>input:</strong> $\left(N, C_{i n}, D, H, W\right)$​</li>
<li><strong>output:</strong> $\left(N, C_{\text {out }}, D_{\text {out }}, H_{\text {out }}, W_{\text {out }}\right)$​</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>感受野(receptive field)可以是<strong>长方形</strong>的</p>
</li>
</ul>
<h2 id="Self-attention"><a href="#Self-attention" class="headerlink" title="Self-attention"></a>Self-attention</h2><ul>
<li><p>作用：在输入为<strong>序列</strong>时对其进行预处理，即通过考虑整个输入的上下文信息对输入进行处理。</p>
<blockquote>
<ul>
<li>将图片某个像素的多个通道抽象为一个vector，也可以把整张图当作m*n个向量的序列。</li>
<li>可以在神经网络<strong>隐层</strong>中使用</li>
<li>现在通常使用self-attention替代RNN</li>
</ul>
</blockquote>
</li>
<li><p>卷积实际上就是简化的self-attention，即卷积是local，但是self-attention是global.</p>
<blockquote>
<ul>
<li>self-attention和<strong>一维</strong>卷积的区别：<a href="https://www.zhihu.com/question/288081659" target="_blank" rel="noopener">https://www.zhihu.com/question/288081659</a></li>
<li>一维卷积的连接强度（权重）是与输入<strong>无关</strong>的，注意力机制的连接强度是与输入<strong>相关</strong>的。</li>
</ul>
</blockquote>
</li>
<li><p>positional encoding：弥补self-attention没有考虑位置信息的问题</p>
</li>
<li><p>由输入得到的Q, K, V分别指Query, Key, Value，矩阵运算示意如下：<a href="https://zhuanlan.zhihu.com/p/47282410" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/47282410</a></p>
<ul>
<li><p>$Q*K$衡量相似度，结果和$V$点乘（求和）是为了强调原始信息。</p>
<blockquote>
<ul>
<li>向量点乘结果大小表示相似度大小</li>
<li>本质上是一个<strong>输入特征加权</strong>的过程</li>
</ul>
</blockquote>
</li>
</ul>
<p><img src="https://pic4.zhimg.com/80/v2-eea2dcbfa49df9fb799ef8e6997260bf_1440w.jpg" alt="img" style="zoom:67%;" /></p>
<p><img src="https://pic4.zhimg.com/80/v2-752c1c91e1b4dbca1b64f59a7e026b9b_1440w.jpg" alt="img" style="zoom:67%;" /></p>
</li>
<li><p>multi-head self-attention：将Q, K, V乘上新矩阵分裂成多个<strong>独立的维度</strong>，最后将各个维度上的Z拼接起来变换回原尺寸，head可以理解成在<strong>多个不同的维度上</strong>提取特征。</p>
<p><img src="https://pic4.zhimg.com/80/v2-3cd76d3e0d8a20d87dfa586b56cc1ad3_1440w.jpg" alt="img" style="zoom: 50%;" /></p>
</li>
<li><p>Self-attention和Attention的区别：<a href="https://blog.csdn.net/At_a_lost/article/details/108469516" target="_blank" rel="noopener">https://blog.csdn.net/At_a_lost/article/details/108469516</a></p>
<p><img src="https://i.loli.net/2021/07/06/irnvSUHRkme4c8J.png" alt="image-20210706224143287" style="zoom: 50%;" /></p>
</li>
</ul>
<h2 id="Transformer"><a href="#Transformer" class="headerlink" title="Transformer"></a>Transformer</h2><ul>
<li><p>输入为独热码，输出的长度由vocabulary决定，即所有<strong>可能词汇</strong>的个数，各个位置上为概率值。</p>
</li>
<li><p><strong>训练时</strong>，decoder每个阶段的输入是<strong>正确的label</strong>(teacher forcing)；<strong>测试时</strong>，使用自身前一阶段的<strong>输出</strong>。</p>
</li>
<li><p>mask self-attention：decoder在处理当前输入时不可能看到下一个输入（当前阶段还没有输出），因此attention只在<strong>左侧范围（含自身）</strong>进行。</p>
</li>
<li><p>Transformer中的Layer Normalization取<strong>同一个样本的不同特征</strong>进行标准化；Batch Normalization取<strong>不同样本的同一个特征</strong>标准化。</p>
<blockquote>
<ul>
<li>LN在<strong>batch较小</strong>或者采用<strong>RNN</strong>等不适合BN的架构时使用</li>
<li>LayerNorm计算解析：<a href="https://blog.csdn.net/weixin_39228381/article/details/107939602" target="_blank" rel="noopener">https://blog.csdn.net/weixin_39228381/article/details/107939602</a></li>
<li>LayerNorm和BatchNorm比较：<a href="https://zhuanlan.zhihu.com/p/54530247" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/54530247</a></li>
</ul>
</blockquote>
</li>
<li><p>机器翻译常采用BLEU score进行评估，但由于其不可微分，故在训练时仍使用交叉熵作为损失函数。</p>
</li>
<li><p>Attention是Transformer中的一个模块</p>
<p><img src="https://pic1.zhimg.com/v2-1c76cb1a90526acd6c6f6f9c6d6c7420_1440w.jpg?source=172ae18b" alt="Attention和Transformer" style="zoom: 25%;" /></p>
</li>
</ul>
<h2 id="Recurrent-Neural-Network"><a href="#Recurrent-Neural-Network" class="headerlink" title="Recurrent Neural Network"></a>Recurrent Neural Network</h2><ul>
<li><p>LSTM是采用RNN思想的另一种<strong>网络架构</strong>（并不是神经元）</p>
</li>
<li><p>RNN通常<strong>不使用</strong><code>ReLu</code>作为激活函数</p>
</li>
<li><p>LSTM中记忆单元存储的值在遗忘门没有打开时，更新操作适合输入流相加，而不是RNN的直接替换，所以能够保证：所有对记忆单元造成了影响的值不会被完全遗忘，从而解决了RNN的梯度消失问题。</p>
<blockquote>
<ul>
<li>梯度消失的本质：距离较远的时间序列的信息难以在参数更新拥有话语权</li>
<li>LSTM仍然可能出现梯度爆炸，因此学习率通常设置的很小。</li>
</ul>
</blockquote>
</li>
<li><p>GRU将输入门和遗忘门联系起来（只剩下两个门），降低了参数量。</p>
</li>
<li><p>RNN下一状态隐层输出：$h_t = \tanh(W_{ih} x_t + b_{ih} + W_{hh} h_{(t-1)} + b_{hh}) $</p>
<ul>
<li><p>需要学习的参数：输入和记忆单元传递使用的权值$W$，两个偏置。</p>
<p><img src="https://i.loli.net/2021/05/18/1VFZxoh5P6EGjBN.png" alt="image-20210518110154693" style="zoom: 50%;" /></p>
</li>
</ul>
</li>
</ul>
<h2 id="Semi-supervised-Learning"><a href="#Semi-supervised-Learning" class="headerlink" title="Semi-supervised Learning"></a>Semi-supervised Learning</h2><ul>
<li><p>纯半监督学习的测试数据<strong>不是</strong>未标注数据，直推学习(transductive)的<strong>测试数据</strong>就是<strong>未标注数据</strong>。</p>
</li>
<li><p>主动学习：逐步扩展有标注数据集（专家协助），力求使用最小的数据量进行训练。</p>
<blockquote>
<p>增加了标注数据量，<strong>不属于</strong>半监督学习。</p>
</blockquote>
</li>
<li><p>生成式模型：基于极大似然思想，代表方法为$EM$法.</p>
<ul>
<li><p><strong>似然</strong>是用样本推测分布（参数），<strong>概率</strong>是用分布（参数）对样本进行预测。</p>
</li>
<li><p><strong>需要先对样本的分布做出假设</strong></p>
</li>
<li><p>每个样本既可以是正类，也可以是负类。</p>
</li>
<li><p>优化函数：$argmax\ \Sigma (P(x|C1)P(C1)+P(x|C2)P(C2))$</p>
<blockquote>
<p>概率值与参数$\theta$有关</p>
</blockquote>
</li>
</ul>
</li>
<li><p><code>Low Density</code>假设：在不同类别的分界处出现样本的概率是很小的（非黑即白）</p>
<ul>
<li>self-learning：不同于主动学习，模型使用<code>pseudo label</code>进行更新。</li>
<li>S3VM</li>
<li>正则化：无标注数据交叉熵（使预测是一个偏态分布）</li>
</ul>
<blockquote>
<p><strong>不</strong>适用于<strong>回归</strong>问题：回归问题的输出是确定值而不是概率，即重新输入模型的值和模型的原输出值相同，因此生成的pseudo value被加入标注数据集<strong>并不能</strong>优化原有参数。</p>
</blockquote>
</li>
<li><p><code>Smoothness</code>假设：相同类别的样本的模型输出应该是相近的</p>
<ul>
<li>Cluster</li>
<li>Graph based</li>
<li>正则化：无标注数据平滑度（保证联系够紧密的才能分为一类）</li>
</ul>
</li>
</ul>
<h2 id="Unsupervised-Learning"><a href="#Unsupervised-Learning" class="headerlink" title="Unsupervised Learning"></a>Unsupervised Learning</h2><p>无监督学习通常应用在数据挖掘领域，在没有标签的数据中找寻内在规律并解决问题。</p>
<h3 id="Cluster"><a href="#Cluster" class="headerlink" title="Cluster"></a>Cluster</h3><ul>
<li><p>聚类可以单独解决一个问题，也可以作为其他方法的<strong>预处理</strong>手段。</p>
</li>
<li><p>聚类最常使用的方法：k-means</p>
<blockquote>
<p><code>kNN</code>（k近邻）算法：懒惰监督学习，根据输入计算出距离最近的<code>k</code>个训练样本，然后取最多的标签作为预测结果。</p>
</blockquote>
</li>
</ul>
<h3 id="PCA"><a href="#PCA" class="headerlink" title="PCA"></a>PCA</h3><ul>
<li><p>通过提取主成分，在丢失<strong>少量信息</strong>的情况下，<strong>大幅度降低</strong>运算复杂度。</p>
</li>
<li><p>线性降维方法：通过<strong>线性变换</strong>（矩阵运算）减少特征维数</p>
</li>
<li><p>主成分本质上就是原成分构成的一组新基</p>
<ul>
<li><p>范数（模长）为1</p>
</li>
<li><p>相互正交（协方差为零/不相关）</p>
</li>
<li><p>新基是原特征间协方差矩阵的特征向量和原特征的内积，按照特征值大小<strong>降序排列</strong>。</p>
<blockquote>
<p>特征值越大，说明该成分对样本特征影响越大（越重要）。</p>
</blockquote>
</li>
</ul>
</li>
<li><p>PCA运算在以构造误差$L=||(x-\bar{x})-\hat{x}||_2$<strong>最小化</strong>为目标时，是<strong>线性单隐层</strong>神经网络的<strong>最优解</strong>。(Autoencoder)</p>
<blockquote>
<p>PCA的最优解对应<strong>最大特征值</strong>，因此可以使用<strong>梯度下降</strong>求解。（但神经网络中通常无法求得最优解）</p>
</blockquote>
</li>
</ul>
<h3 id="SVD"><a href="#SVD" class="headerlink" title="SVD"></a>SVD</h3><ul>
<li>也是一种降维压缩的办法，使用不同秩的奇异值矩阵保留不同密度的信息。（秩越大保存的信息越多）</li>
</ul>
<p><img src="https://pic2.zhimg.com/80/v2-74f7d2430ace69c9cd6b963eb58a5079_1440w.jpg" alt="img" style="zoom: 25%;" /></p>
<h3 id="Word-Embedding"><a href="#Word-Embedding" class="headerlink" title="Word Embedding"></a>Word Embedding</h3><ul>
<li><p>词向量</p>
<ul>
<li><p>基于统计：阅读大量文章，经常一起出现的词所对应的词向量应该有<strong>较高相似度</strong>。</p>
</li>
<li><p>基于预测：使用词的上下文信息建立神经网络，例如前一个单词的<strong>独热编码</strong>作为输入来预测下一个单词。此时神经网络的输出是下一个单词各个类别的概率，通过训练使某个词对应的概率最大化，然后将改神经网络的第一个隐层的<strong>输入</strong>作为词向量。</p>
<blockquote>
<p>因为相似的词需要得到相似的输出，所以第一个隐层的输入作为词向量可以保证它们的相似度。</p>
</blockquote>
</li>
</ul>
</li>
<li><p>涉及到共享权值时，梯度下降更新时需要<strong>减去所有</strong>共享的权值的偏微分与学习率的乘积。</p>
<blockquote>
<ul>
<li>卷积反向传播更新参数<strong>同理</strong></li>
<li>不可导/多微分反向传播：<a href="https://blog.csdn.net/qq_21190081/article/details/72871704" target="_blank" rel="noopener">https://blog.csdn.net/qq_21190081/article/details/72871704</a></li>
</ul>
</blockquote>
</li>
<li><p>共享权值的作用</p>
<ul>
<li><strong>上下文相同</strong>的单词具有<strong>同样的编码</strong>（即相同的权重）</li>
<li>减小模型参数量</li>
</ul>
</li>
</ul>
<h2 id="Self-supervised-Learning"><a href="#Self-supervised-Learning" class="headerlink" title="Self-supervised Learning"></a>Self-supervised Learning</h2><ul>
<li><strong>自监督学习</strong>使用的标注来自于数据本身，而不是人工标注，因此属于<strong>无监督学习</strong>。</li>
</ul>
<h3 id="Generative-Adversarial-Network-GAN"><a href="#Generative-Adversarial-Network-GAN" class="headerlink" title="Generative Adversarial Network (GAN)"></a>Generative Adversarial Network (GAN)</h3><ul>
<li><p>Generative Model可以针对<strong>同一个输入</strong>而产生<strong>不同的合法输出</strong>，使其符合一定分布。</p>
<ul>
<li>适合于创造性的工作，例如画画、问答等。</li>
<li>因为<strong>监督式学习</strong>强调有固定的某一个输出，因为会导致模型对某一个输入对应的输出结果“两边讨好”，例如人物分裂、图像模糊等情况。</li>
<li>GANs are <strong>unsupervised learning</strong> algorithms that use a <strong>supervised</strong> loss as part of the training.</li>
</ul>
<blockquote>
<p>GAN的随机性：输出的答案可能有很多，且<strong>都是正确的</strong>，即属于某个分布。但是对于一个具体GAN模型而言，它对一个特定输入<strong>只会产生</strong>它学习到的生成结果，但可能另外一个GAN就是<strong>不同的结果</strong>，但是两个结果<strong>同分布</strong>，例如都是漫画。因此，可以将<code>Discriminator</code>理解成一个放宽了要求、更加灵活的<strong>评价指标</strong>。</p>
</blockquote>
</li>
<li><p>GAN的目标是使生成的结果和真实情况尽量接近（<strong>不是完全一样</strong>），因此<code>Generator</code>需要生成和真实数据<code>Divergence</code>小的结果，而<code>Discriminator</code>则是将它们区分开。</p>
</li>
<li><p><code>JS Divergence</code>在生成结果和真实数据分布交集较小（或没有交集）时恒为$log2$​​，因此朴素的<code>Discriminator</code>尽管目标函数和<code>JS Divergence</code>相关，也不能<strong>有效</strong>判定生成结果和真实数据是否同分布。</p>
<blockquote>
<ul>
<li>正确<strong>不一定</strong>有效</li>
<li>恒为$log2$​导致生成器梯度为0</li>
</ul>
</blockquote>
</li>
<li><p><code>Discriminator</code>起初被设置为二分类器，但是由于数据规模的限制很容易过拟合。进一步导致无法<strong>有效</strong>鉴别生成和真实结果，只是记住了真实数据来直接判定生成结果。</p>
</li>
<li><p>理论上，每一轮迭代<strong>都需要</strong>重新训练<code>Discriminator</code>，但是实际上由于计算量过大都是直接使用前一轮迭代的结果。</p>
</li>
<li><p>使用<code>Wasserstein Distance(WGAN)</code>替代<code>JS Divergence</code>衡量生成结果和真实数据之间的差异可以提高模型性能</p>
<ul>
<li><code>WGAN</code>解析：<a href="https://zhuanlan.zhihu.com/p/25071913" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/25071913</a></li>
</ul>
<blockquote>
<p>不同的<code>Divergence</code>对应了不同的损失函数（目标函数）</p>
<p><img src="https://i.loli.net/2021/09/09/5JYszjdgB2KeZ6C.png" alt="image-20210909214409320"></p>
<ul>
<li>$E[x]$指期望</li>
<li>大多数时候两个模型的损失函数并没有较大区别，仅是优化方向不同。</li>
<li><code>WGAN</code>生成器损失函数应为：$-\mathcal{L}_{\mathrm{D}}^{\text {WGAN }}$​​​，由于删掉了<code>Sigmoid</code>，此时<strong>判别器神经网络</strong>的输出是distance大小<strong>取反</strong>而不是概率值，故需要生成器对距离进行<strong>最小化</strong>，即对distance<strong>最小化</strong>。</li>
</ul>
</blockquote>
</li>
<li><p>生成方式</p>
<ul>
<li>unconditional: 仅向<code>Generator</code>喂入分布中采样的随机向量$Z$</li>
<li>conditional: 在$Z$的基础上增加条件$X$作为限定<ul>
<li>要求<code>Discriminator</code>同时根据生成结果$Y$和$X$对质量进行判定</li>
</ul>
</li>
</ul>
</li>
<li><p><code>Cycle GAN</code>：对生成结果在使用<code>Discriminator</code>鉴定的基础上，将其通过另一个<code>Generator</code>复原与原输入比较来衡量质量。常用于跨域变换，例如真实图像转化为漫画。</p>
<blockquote>
<p>同样的，对于还原的结果可以再次使用<strong>第一个</strong><code>Generator</code>进行变换，从而对<strong>第二个</strong><code>Genarator</code>进行训练。</p>
</blockquote>
</li>
</ul>
<h3 id="Pre-train"><a href="#Pre-train" class="headerlink" title="Pre-train"></a>Pre-train</h3><ul>
<li><p>BERT本质上是一个Transformer Encoder，<strong>输入输出格式相同</strong>。</p>
</li>
<li><p>BERT预训练机制：<strong>创造有label的任务</strong></p>
<ul>
<li><p>Masking Input：将<strong>无label</strong>的数据进行<strong>随机遮挡</strong>或<strong>字符替换</strong>，即使某些位置<strong>失去意义</strong>，然后将这些位置对应的BERT输出通过<code>linear+softmax</code>进行处理，预测可能是什么字符。</p>
</li>
<li><p>Next Sentence Prediction：在两个句子开始处增加<code>[CLS]</code>和之间增加特殊的<code>[SEP]</code>字符，然后将其输入BERT，根据<code>[CLS]</code>对应输出通过<code>linear+softmax</code>判定是否连接。</p>
<blockquote>
<ul>
<li>实验证明：预测下一个句子的预训练方式<strong>帮助不大</strong></li>
<li>改进：预测句子顺序(ALBERT)</li>
</ul>
</blockquote>
</li>
</ul>
</li>
<li><p>Downstream Task：通过使用预训练的BERT模型作为Encoder，添加不同的尾部结构，使用特定任务下有标注的数据即可刺激BERT模型进行适配，即<code>fine tune</code>.</p>
<ul>
<li><p>Text Classification：对<code>[CLS]</code>进行分类预测</p>
<p><img src="https://i.loli.net/2021/09/13/mNQtYjHu4GZWDqA.png" alt="image-20210913115044757" style="zoom:50%;" /></p>
</li>
<li><p>POS Tagging（词性标注）：对每一个BERT的输出进行分类预测</p>
<p><img src="https://i.loli.net/2021/09/13/QO7XLte8mFHudhx.png" alt="image-20210913115112578" style="zoom:50%;" /></p>
</li>
<li><p>NLI（自然语言推断）：判断<code>premise</code>和<code>hypothesis</code>之间的关系</p>
<p><img src="https://i.loli.net/2021/09/13/Qjwx3aMZNOGuysC.png" alt="image-20210913115221487" style="zoom:50%;" /></p>
</li>
<li><p>Extraction-based QA：答案在原文中的问答。输入原文和问题，输出为两个整数，表示token在原文中的位置。</p>
<p><img src="https://i.loli.net/2021/09/13/WzxwAjPsk8CdEqN.png" alt="image-20210913115300620" style="zoom:50%;" /></p>
</li>
</ul>
</li>
<li><p>BERT由于使用了self-attention，因此生成的Embedding都是上下文相关的(contextualized word embedding)，例如“果”在可能有<strong>多个不同</strong>的Embedding.</p>
</li>
<li><p>多语言BERT：对不同语言的Embedding会有较大距离，例如中文的苹果和英文的apple实际上是不同的。</p>
<blockquote>
<p>通过添加<strong>位移向量</strong>可以实现<strong>机器翻译</strong></p>
</blockquote>
</li>
<li><p>GPT：采用不同于BERT的预训练机制，即预测下一个Token.</p>
</li>
</ul>
<h3 id="Auto-encoder"><a href="#Auto-encoder" class="headerlink" title="Auto-encoder"></a>Auto-encoder</h3><ul>
<li><p>Auto-encoder实际上也是一种<strong>自监督式学习</strong></p>
</li>
<li><p>Auto-encoder的架构里实际上<strong>有一个Decoder</strong></p>
<p><img src="https://i.loli.net/2021/09/13/HY3qr2bROTk1m4L.png" alt="image-20210913114036754" style="zoom:50%;" /></p>
<blockquote>
<ul>
<li>通过对复杂的高维输入进行降维，从而得到Embedding</li>
<li><code>vector+Decoder</code>实际上就是一个Genarator</li>
</ul>
</blockquote>
</li>
<li><p>通过处理和控制Embedding的形式可以完成不同的任务</p>
<ul>
<li>Feature Disentanglement：将Embedding中不同的特征进行分类，可以实现不同数据的组合，例如人声的交换。</li>
<li>Discrete Latent Representation：要求Embedding的特定形式。例如独热码，则Auto-encoder便通过自监督学会了分类。</li>
</ul>
</li>
<li><p>对于极端的样本不平衡问题，可以采用Auto-encoder进行异常检测。此时数据集中<strong>可能只有一个类别</strong>，通过衡量测试数据的<code>reconstruction loss</code>，若较大则说明是离群点。</p>
<p><img src="https://i.loli.net/2021/09/13/XLaxfthuv1zUpsR.png" alt="image-20210913114814865" style="zoom:50%;" /></p>
</li>
</ul>
<h2 id="Domain-Adaptation"><a href="#Domain-Adaptation" class="headerlink" title="Domain Adaptation"></a>Domain Adaptation</h2><ul>
<li><p>Domain Adaptation和自监督都属于Transfer Learning</p>
</li>
<li><p>Domain Shift：训练数据和测试数据有不同的分布</p>
</li>
<li><p>Domain Adaptation属于Transfer Learning</p>
</li>
<li><p>Domain Adversarial Training：一种对抗训练方式（GAN也是一种）</p>
<p><img src="https://i.loli.net/2021/09/23/nwzyUVPOIuiCgNW.png" alt="image-20210923193707189" style="zoom:50%;" /></p>
<ul>
<li>Label Predictor：对source domain中的数据Embedding进行正确分类</li>
<li>Domain Classifier：将两种数据的Embedding区分开来</li>
</ul>
<blockquote>
<p>由于目标是最小化$(L-L_d)$，则$L_d$可能会被过分放大，<strong>即source被判定为target且target被判定为source</strong>，故该训练方式<strong>无法取得</strong>最优效果。</p>
</blockquote>
</li>
<li><p>Domain Generalization：target<strong>完全未知</strong>时增强模型的泛化能力，常见思路类似于data augmentation.</p>
</li>
</ul>
<h2 id="Explainable-Machine-Learning"><a href="#Explainable-Machine-Learning" class="headerlink" title="Explainable Machine Learning"></a>Explainable Machine Learning</h2><ul>
<li><p>Local Explanation：找出数据中对预测起到关键作用的部分</p>
<ul>
<li>设置一个自定义大小、颜色的蒙版，根据不同的摆放位置判断某区域是否关键。</li>
<li>随机扰动某个pixel，根据结果改变的梯度判断其重要性高低，最终得到saliency map.<ul>
<li>由于gradient saturation的存在（大象鼻子超过一定长度后对判定没有帮助），会导致saliency map不准确的情况，可以使用smooth gradient，即在输入中添加多种噪声生成多张saliency map然后取均值作为最终结果。</li>
<li>实现时，只需要求损失函数对输入的梯度大小即可，<strong>不需要</strong>真正改变输入。</li>
</ul>
</li>
</ul>
</li>
<li><p>Global Explanation：通过调整输入，让模型得到对某种结果反应最大（概率值最大）的输出，通过输出判断。</p>
<blockquote>
<p>local是让模型说一张图为什么是茂，global是让模型说觉得猫长什么样子。</p>
</blockquote>
</li>
</ul>
<h2 id="Attack-ML-Model"><a href="#Attack-ML-Model" class="headerlink" title="Attack ML Model"></a>Attack ML Model</h2><ul>
<li><p>损失函数&amp;目标函数&amp;性能表现</p>
<ul>
<li>Loss Function：目标函数在有约束的条件下<strong>需要最小化</strong>的函数</li>
<li>Object Function：需要被优化的函数（最大/最小化均可）</li>
<li>Accuracy/IoU/F1 etc.：供比较的模型的性能指标</li>
</ul>
<blockquote>
<p><strong>Q：为什么不用性能表现作为目标函数？</strong></p>
<p>A：性能表现是<strong>以数据项为单位</strong>的，粒度过粗。例如100张图片分类任务，模型多次迭代后正确率均在90%左右，实际上这90个正确标签<strong>不一定</strong>是相同的，但是准确率不变，<strong>无法通过</strong>梯度下降对模型进行优化。</p>
</blockquote>
</li>
<li><p>攻击时模型的参数固定，改变的是<strong>输入的样本</strong>。</p>
<ul>
<li><p>通常由梯度下降进行优化</p>
<ul>
<li><p>损失函数：$L\left(x^{\prime}\right)=-C\left(y^{\prime}, y^{\text {true }}\right)+C\left(y^{\prime}, y^{\text {false }}\right)$</p>
<ul>
<li>$x’$：输入样本</li>
<li>$y’$：输出结果</li>
<li>$C$：交叉熵损失函数</li>
</ul>
</li>
<li><p>目标函数：$x^{*}=\arg \min _{d\left(x^{0}, x^{\prime}\right) \leq \varepsilon} L\left(x^{\prime}\right)$​</p>
<blockquote>
<p>对benign input进行变化得到理想的attacked input</p>
</blockquote>
</li>
</ul>
</li>
</ul>
</li>
<li><p>衡量benign input和attacked input时，根据不同的数据类型采取不同的指标，例如图像根据直观来说：各个像素都变化一点比局部巨大变化更容易隐藏，因此使用<code>L-infinity</code>.</p>
</li>
<li><p>白盒攻击：已知模型结构和参数，因此可以通过梯度下降求出最优的噪声输入。</p>
<ul>
<li><p>FGSM(Fast Gradient Sign Method)</p>
<ul>
<li>$x^{*} \leftarrow x^{0}-\varepsilon \Delta x$</li>
<li>$\Delta x=\left[\begin{array}{c}\operatorname{sign}\left(\partial L / \partial x_{1}\right) \\ \operatorname{sign}\left(\partial L / \partial x_{2}\right) \\ \operatorname{sign}\left(\partial L / \partial x_{3}\right) \\ \vdots\end{array}\right]$only have $+1$ or $-1$​</li>
<li>由于只更新一次，故所有维度的值都小于$\epsilon$，不用担心<code>L-infinity</code>溢出.</li>
</ul>
</li>
<li><p>Iterative FGSM：多次使用FGSM对输入进行更改，当<code>L-infinity</code>过大时进行裁剪。</p>
<p><img src="https://i.loli.net/2021/09/22/srSLnFR8ejh3xEZ.png" alt="image-20210922214200616" style="zoom:50%;" /></p>
</li>
</ul>
</li>
<li><p>黑盒攻击：（使用相同数据集）训练proxy model进行攻击（白盒攻击），然后使用得到的样本攻击黑盒模型。</p>
<ul>
<li>proxy model的网络模型和目标模型<strong>不一定相同</strong></li>
<li>使用<strong>集成攻击</strong>，即同时得到对多种模型都有效的输入，可以提高攻击的成功率。</li>
</ul>
</li>
<li><p>被动防御：不修改原始模型，通常在输入模型前增加filter(eg. smoothing/padding/reshape)</p>
</li>
<li><p>主动防御：类似数据增强，在训练时对模型进行攻击，把有害样本加入训练集对模型进行再次训练。</p>
</li>
</ul>
<h2 id="Reinforcement-Learning"><a href="#Reinforcement-Learning" class="headerlink" title="Reinforcement Learning"></a>Reinforcement Learning</h2><ul>
<li><p>适用场景：没有正确答案，只有好与坏。（多种正确答案，类似于GAN）</p>
</li>
<li><p>核心概念</p>
<p><img src="https://i.loli.net/2021/09/26/LTdKt569WPwsICS.png" alt="image-20210926195502290" style="zoom:50%;" /></p>
<ul>
<li><p>Actor/Agent/Policy Network：被训练的用于预测的核心模型，输出各个action的概率，本质上是<strong>分类器</strong>。</p>
</li>
<li><p>action：通过随机sample得到的输出。实践时训练使用<strong>随机</strong>策略，推断使用均值或概率最大的动作。</p>
<ul>
<li>训练时增加可能采取的动作种类，从而得到更全面的reward评估策略。</li>
<li>还可以通过Exploration策略，即在actor中参数中增加噪声等操作获取更加多样化的动作。</li>
</ul>
<blockquote>
<p>与GAN不同，RL模型的输出在训练<strong>固定随机种子</strong>情况下<strong>也不固定</strong>，因此<strong>优化</strong>过程比较困难。</p>
</blockquote>
</li>
<li><p>episode：活动（eg. 游戏）从开始到结束的整个过程</p>
</li>
<li><p>reward：每一个action对应的奖励分数</p>
</li>
<li><p>return/total reward：整个episode奖励分数总和，即$R=\sum_{t=1}^{T} r_{t}$.</p>
</li>
</ul>
</li>
<li><p>Policy Gradient：根据不同的情况输出下一步动作的优化策略，<strong>不考虑$Q$和$V$.</strong></p>
<p><img src="https://i.loli.net/2021/09/26/HOf8FMW3zad7Rls.png" alt="image-20210926202234409" style="zoom:50%;" /></p>
<p><img src="https://i.loli.net/2021/09/26/jlTisyeYgDR7zKX.png" alt="image-20210926202645066" style="zoom:50%;" /></p>
<ul>
<li>$e_n$衡量输出$a_n$和标签$\hat{a_n}$的差异（交叉熵），通过调整$A_n$来表示对该动作的评估。<ul>
<li>$A_n$越大，说明需要<strong>最小化</strong>$e_n$，即增大该动作出现的概率，否则减小。</li>
<li>$e_n$还可以表示采取当前动作的“吃惊程度”，由$-log(prob)$表示，当采取该措施的概率<strong>越小</strong>，则$e_n$<strong>越大</strong>，若此时reward大，则$A_n$就大，从而对<strong>参数更新的影响</strong>就大。</li>
<li><a href="https://www.jianshu.com/p/2ccbab48414b" target="_blank" rel="noopener">https://www.jianshu.com/p/2ccbab48414b</a></li>
</ul>
</li>
<li>训练过程中每一次更新参数都需要用<strong>最新的$\theta$重新交互获取训练数据</strong><ul>
<li>旧参数的sample策略可能和TD-error不符，导致目前的决策退化。</li>
<li>参数的更新只需要通过$e_n$和$A_n$计算loss即可，环境、<strong>动作序列信息</strong>都已经被归纳。</li>
</ul>
</li>
<li>On-policy and Off policy<ul>
<li>On：更新的模型和交互的模型是同一个，通常效果更好。</li>
<li>Off：减小每个episode收集数据的工作量，从而一直使用<strong>一组数据</strong>进行训练。<ul>
<li>PPO important sampling：对各个action概率进行规范化，即$P(target)/P(template)$.</li>
<li><a href="https://zhuanlan.zhihu.com/p/111049450" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/111049450</a></li>
</ul>
</li>
</ul>
</li>
<li>Version 0：$A_n=r_n$，此时模型只关注当前的状态$s_n$、当前动作$a_n$和能够获得的奖励$r_n$.</li>
<li>Version 1：$A_n=G_n=\Sigma^N_{i=n}r_i$，即当前步到最后的奖励之和，又称Cumulated Reward。</li>
<li>Version 2：$A_n=G_n’=\Sigma^N_{i=n}\gamma^{i-n}r_i$，通过$\gamma^{i-n}$使距离远的reward效果下降，又称Discounted Cumulated Reward。</li>
<li>Version 3：$A_n=G_n’-b$，通过减去baseline从而标准化奖励的“相对好坏”<strong>（有正有负）</strong>，其中$b$是$G_n’$的最小值。</li>
</ul>
<blockquote>
<p>此后的Version实际上<strong>并不属于</strong>PG</p>
</blockquote>
<ul>
<li><p>Version 3.5：$A_n=G_n’-b_n$，其中$b_n=V^\theta(s_n)$.</p>
</li>
<li><p>Version 4(Advantage Actor-Critic)：$A_n=TD-error=r_n+V^\theta(s_{n+1})-V^\theta(s_t)$，即考虑$a_t$后直接对其reward进行标准化，从而评估$a_t$的好坏。</p>
<p><img src="https://pic1.zhimg.com/80/v2-06c9787f9cd9a71d92ce0bbeb871af60_1440w.jpg" alt="img" style="zoom:50%;" /></p>
</li>
</ul>
</li>
<li><p>Actor-Critic：评估actor从某个状态<strong>到终点</strong>能够获得的reward的<strong>期望</strong>，记为$V^\theta(s)$，衡量<strong>状态的好坏</strong>。</p>
<blockquote>
<p>Q评估actor采取某个动作后走到终点能够获得的reward的期望，衡量<strong>动作的好坏</strong>。</p>
<ul>
<li>$Q\rightarrow V$：$v_{\pi}(s)=\sum_{a \in A} \pi(a \mid s) q_{\pi}(s, a)$</li>
<li>$V\rightarrow Q$：$q_{\pi}(s, a)=R_{s}^{a}+\gamma \sum_{s^{\prime}} P_{ss’}^{a} v_{\pi}\left(s^{\prime}\right)$</li>
</ul>
</blockquote>
<p><img src="https://i.loli.net/2021/09/26/LMkBrs8V5odmIeR.png" alt="image-20210926204751057" style="zoom:50%;" /></p>
<ul>
<li><p>Monte-Carlo(MC)：将Discounted Cumulated Reward的<strong>期望值</strong>作为$V^\theta(s)$</p>
</li>
<li><p>Tempered-different(TD)：根据$s_t,a_t,r_t,s_{t+1}$计算$V^\theta(s)$</p>
<p>$V^{\theta}\left(s_{t}\right)=r_{t}+\gamma r_{t+1}+\gamma^{2} r_{t+1} \ldots$<br>$V^{\theta}\left(s_{t+1}\right)=r_{t+1}+\gamma r_{t+2}+\cdots$<br>$V^{\theta}\left(s_{t}\right)=\gamma V^{\theta}\left(s_{t+1}\right)+r_{t} \Rightarrow V^{\theta}\left(s_{t}\right)-\gamma V^{\theta}\left(s_{t+1}\right) \leftrightarrow r_{t}$</p>
<blockquote>
<ul>
<li>$r_t$和$s_t$和$a_t$强相关，但<strong>不是决定</strong>。（还与$t$前的动作有关）</li>
<li><a href="https://zhuanlan.zhihu.com/p/110998399" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/110998399</a></li>
</ul>
</blockquote>
</li>
<li><p>实现时，因为Policy Network和Actor-Critic都以<strong>状态$s$</strong>作为输入，因此可以共享参数(Feature Extractor)。</p>
<p><img src="https://i.loli.net/2021/09/26/X2xyT9Kgl51uDkf.png" alt="image-20210926205527054" style="zoom: 50%;" /></p>
</li>
<li><p>Sparse Reward：多数时候的reward为0，导致$A_n$基本相同，各个动作的好坏难以区分。</p>
</li>
<li><p>reward shaping：使用domain knowledge自定义extra reward，解决sparse reward问题。</p>
<ul>
<li>Curiosity策略：让actor必须探索新的事物，且这个新需要<strong>有意义</strong>。</li>
</ul>
</li>
<li><p>Imitation Learning：模仿人在真实环境的行为(expert)，从而解决真实世界难以定义reward的情况。</p>
<ul>
<li>监督学习：完全模仿，即Behavior Cloning，在面对未知情况时表现可能不好。</li>
</ul>
</li>
<li><p>Inverse RL(IRL)：让机器自己定义reward，可以通过环境和expert<strong>反推出</strong>reward function.</p>
<p><img src="https://i.loli.net/2021/09/27/59KtQxDNSeaohrT.png" alt="image-20210927102153539" style="zoom:50%;" /></p>
<ul>
<li><p>首要原则：expert的reward高于agent，即$\sum_{n=1}^{K} R\left(\hat{\tau}_{n}\right)&gt;\sum_{n=1}^{K} R(\tau)$.</p>
</li>
<li><p>IRL和GAN本质上是一样的</p>
<p><img src="https://i.loli.net/2021/09/27/Jqp8LzmX5kIMPn3.png" alt="image-20210927102500622" style="zoom:50%;" /></p>
<ul>
<li>此时actor和reward function<strong>互为</strong>对方的environment</li>
<li>reward高低的衡量方式与score类似，可以有多种。</li>
<li>IRL中reward function是从<strong>专家数据</strong>中学到奖励的规律，但是critic的$V^\theta(s)$是在<strong>actor与环境的交互</strong>中学到的奖励规律：<a href="https://zhuanlan.zhihu.com/p/59649635" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/59649635</a></li>
<li>从IRL看到，强化学习中也可以有宽泛的“标签”（并非人为标记），因此GAN可以理解成RL的一种<strong>自监督训练方式</strong>，一种<strong>双向强化学习</strong>。</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="Life-Long-Learning"><a href="#Life-Long-Learning" class="headerlink" title="Life Long Learning"></a>Life Long Learning</h2><ul>
<li><p>终身学习又称Continuous Learning、Continual Learning</p>
</li>
<li><p>Catastrophic Forgetting：在学习新任务后忘记已学习的任务</p>
<ul>
<li>模型<strong>有能力</strong>学会多个任务：多种数据同时训练(multi-task)时，模型表现很好，且通常作为LLL的upper bound.</li>
</ul>
</li>
<li><p>LLL&amp;Transfer Learning：前者希望模型在<strong>旧任务和新任务</strong>上表现<strong>都很好</strong>，而<strong>后者</strong>侧重点是<strong>新任务</strong>。</p>
</li>
<li><p>评估方式</p>
<p><img src="https://i.loli.net/2021/09/29/BmkPpoScafVn7gl.png" alt="image-20210929152939923" style="zoom: 67%;" /></p>
<ul>
<li>Accuracy $=\frac{1}{T} \sum_{i=1}^{T} R_{T, i}$：表示模型在完成<strong>所有任务</strong>的学习后准确率大小</li>
<li>Backward Transfer $=\frac{1}{T-1} \sum_{i=1}^{T-1} (R_{T, i}-R_{i, i})$：表示模型在学习完后<strong>所有任务</strong>后，和刚学习完<strong>各个任务</strong>的性能比较（<strong>通常为负</strong>）</li>
<li>Forward Transfer $=\frac{1}{T-1} \sum_{i=2}^{T} (R_{i-1, i}-R_{0, i})$：表示模型在学习<strong>某个任务前</strong>在该任务上的性能表现</li>
</ul>
</li>
<li><p>解决办法</p>
<p><img src="https://i.loli.net/2021/09/29/53STDYZaBx2bANr.png" alt="4-Figure1-1" style="zoom:67%;" /></p>
<ul>
<li><p>Regularization-based(Selective Synaptic Plasticity)：在<strong>新任务的损失函数</strong>上增加正则项，从而<strong>避免</strong>新参数和原参数<strong>差异过大</strong>，即$\left.L^{\prime}(\boldsymbol{\theta})=L(\boldsymbol{\theta})+\lambda \sum_{i} b_{i} ( \theta _ { i }-\theta_{i}^{b}\right)^{2}$.</p>
<ul>
<li><p>$b_i$叫做guardiance，表示$\theta_i^b$对模型性能的<strong>重要性</strong>，通过计算得到。</p>
<blockquote>
<p>如果通过学习的话，loss最小化的目标会促使网络将所有的$b_i$直接设置成0，与不正则化相同。</p>
</blockquote>
</li>
<li><p>当$b_i$过大时，会导致模型难以学习新任务，即intransigence.</p>
</li>
<li><p>通过$\lambda$和$b$<strong>两个</strong>参数控制参数更新程度</p>
</li>
</ul>
</li>
<li><p>Additional Neural Resource Allocation：<strong>隔离</strong>每个任务使用到的神经元资源，例如Progressive Neural Network在学习新任务时就增加新的神经元，使其处理已有神经元的输出，从而达到<strong>跨域知识共享</strong>目的。</p>
<p><img src="https://i.loli.net/2021/09/29/4nSB23WH9aJzAlX.png" alt="image-20210929154736169" style="zoom: 67%;" /></p>
<ul>
<li><a href="https://blog.acolyer.org/2016/10/11/progressive-neural-networks/?utm_source=tuicool&amp;utm_medium=referral" target="_blank" rel="noopener">https://blog.acolyer.org/2016/10/11/progressive-neural-networks/?utm_source=tuicool&amp;utm_medium=referral</a></li>
</ul>
</li>
<li><p>Memory Reply：在学习某个任务时同时训练数据生成器，这样就不用存储训练数据而只存储生成器，即可在模型学习新任务时输入已学习任务的数据。</p>
</li>
</ul>
</li>
<li><p>Curriculum Learning：研究任务的<strong>学习顺序</strong>对模型性能的影响</p>
</li>
</ul>
<h2 id="Network-Compression"><a href="#Network-Compression" class="headerlink" title="Network Compression"></a>Network Compression</h2><ul>
<li><p>压缩目的：latency&amp;privacy</p>
</li>
<li><p>网络剪枝：在给定数据集上将模型计算过程中绝对值较小的参数<strong>或</strong>多次为0的神经元进行删除，然后将小网络再次训练。（以上过程可迭代）</p>
<ul>
<li>实践中，“删除”操作通过将其置为恒0实现。</li>
<li>神经元是<strong>一组</strong>参数，故修剪神经元通常比修建参数更易实现。</li>
<li>参数的重要性也可以通过Life-long learning方法衡量</li>
</ul>
<blockquote>
<p><strong>Q：为什么不直接训练较小的网络？</strong></p>
<p>A：</p>
<ul>
<li>剪枝后的网络结构通常不规则，很难直接构造。</li>
<li>工程经验表明：小网络很难通过优化取得和大网络剪枝相同的效果。（大乐透假说：大网络可以理解成多个小网络的组合，“开奖”几率<strong>更大</strong>）</li>
</ul>
</blockquote>
</li>
<li><p>知识蒸馏：用小网络去学习大网络的<strong>完整输出</strong>（eg. 各个label的概率分布），和直接用数据训练小网络不同。</p>
<ul>
<li>使用<strong>集成学习模型</strong>作为大网络可以有效提高小网络的性能</li>
<li>Temperature for Softmax：在输入softmax层前将概率值除以超参数$T(Temperature)$，避免大网络的输出变为one-hot，即需要和正确标签保持一定的差异。</li>
<li>在student（小网络）和teacher（大网络）差异过大时，可以添加中介网络过渡。</li>
</ul>
</li>
<li><p>参数量化</p>
<ul>
<li>改变数据类型，eg. float32 to float16.</li>
<li>权值聚类，最终所有的同类权值均取平均值。（类似colormap）<ul>
<li>可以使用Huffman Coding进一步优化</li>
</ul>
</li>
</ul>
</li>
<li><p>调整网络结构<strong>（最有效）</strong></p>
<ul>
<li><p>在隐层间插入含$K$个神经元的全连接层，通过控制$K$来减少参数量。</p>
<p><img src="https://i.loli.net/2021/05/18/cq1yjMaveILkTzd.png" alt="image-20210518105034732" style="zoom:50%;" /></p>
</li>
<li><p>卷积分解：depthwise+pointerwise</p>
<ul>
<li>depthwise捕捉<strong>各个通道内</strong>的模式</li>
<li>pointwise捕捉<strong>跨通道</strong>的模式</li>
</ul>
<p><img src="https://i.loli.net/2021/05/18/WXJ4PCbVIctwEsS.png" alt="image-20210518105117502" style="zoom:50%;" /></p>
<blockquote>
<p><a href="https://medium.com/@zurister/depth-wise-convolution-and-depth-wise-separable-convolution-37346565d4ec" target="_blank" rel="noopener">https://medium.com/@zurister/depth-wise-convolution-and-depth-wise-separable-convolution-37346565d4ec</a></p>
</blockquote>
</li>
<li><p>动态计算</p>
<ul>
<li><p>根据环境限制从存储的多个model中选择（内存开销大）</p>
</li>
<li><p>在中间层增加分类器，根据实际情况选择从哪一层直接进行预测（也可以是其他操作）。</p>
<blockquote>
<p>要求<strong>浅层</strong>网络也要提取<strong>深层</strong>信息，可能对<strong>模型整体性能</strong>造成影响。</p>
</blockquote>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a href="https://speech.ee.ntu.edu.tw/~hylee/ml/2021-spring.html" target="_blank" rel="noopener">Hung-yi Lee Machine Learning Course, Spring 2021.</a></li>
</ul>

    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2021/06/23/OS-Course-Note/" rel="prev" title="OS Course Note">
      <i class="fa fa-chevron-left"></i> OS Course Note
    </a></div>
      <div class="post-nav-item">
    <a href="/2021/06/23/Airbnb-Data-Analysis/" rel="next" title="Airbnb Data Analysis">
      Airbnb Data Analysis <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



        </div>
        
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Silence Jiang</span>
</div>

<div class="powered-by">
<i class="fa fa-user-md"></i><span id="busuanzi_container_site_uv">
  Visitors: <span id="busuanzi_value_site_pv"></span>
</span>
</div>

<div class="theme-info">
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
    <span title="Symbols count total">106.1k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="Reading time total">3:24</span>
  <div class="powered-by"></div>
</div>
  <div class="powered-by">
  </div>

        








      </div>
    </footer>
  </div>

  
  <script defer src="//cdn.jsdelivr.net/npm/three@0/build/three.min.js"></script>
    <script defer src="/lib/three/three-waves.min.js"></script>
  <script src="/lib/anime.min.js"></script>

<script src="/js/utils.js"></script>


<script src="/js/next-boot.js"></script>


  











<script>
document.querySelectorAll('.pdfobject-container').forEach(element => {
  let url = element.dataset.target;
  let pdfOpenParams = {
    navpanes : 0,
    toolbar  : 0,
    statusbar: 0,
    pagemode : 'thumbs',
    view     : 'FitH'
  };
  let pdfOpenFragment = '#' + Object.entries(pdfOpenParams).map(([key, value]) => `${key}=${encodeURIComponent(value)}`).join('&');
  let fullURL = `/lib/pdf/web/viewer.html?file=${encodeURIComponent(url)}${pdfOpenFragment}`;

  if (NexT.utils.supportsPDFs()) {
    element.innerHTML = `<embed class="pdfobject" src="${url + pdfOpenFragment}" type="application/pdf" style="height: ${element.dataset.height};">`;
  } else {
    element.innerHTML = `<iframe src="${fullURL}" style="height: ${element.dataset.height};" frameborder="0"></iframe>`;
  }
});
</script>


<script>
if (document.querySelectorAll('pre.mermaid').length) {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mermaid@8/dist/mermaid.min.js', () => {
    mermaid.initialize({
      theme    : 'forest',
      logLevel : 3,
      flowchart: { curve     : 'linear' },
      gantt    : { axisFormat: '%m/%d/%Y' },
      sequence : { actorMargin: 50 }
    });
  }, window.mermaid);
}
</script>


  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/valine@1/dist/Valine.min.js', () => {
    new Valine(Object.assign({
      el  : '#valine-comments',
      path: location.pathname,
    }, {"enable":true,"appId":"GMneVEFPu4TwpvejAPqllWGc-gzGzoHsz","appKey":"5eNvc7SV1dxRT000WSXjRDuD","placeholder":"Just write what you'd like to write.","avatar":"mm","meta":["nick","mail"],"pageSize":10,"language":"en","visitor":false,"comment_count":true,"recordIP":false,"serverURLs":null}
    ));
  }, window.Valine);
});
</script>

  <!-- 背景动画 -->
  <!-- three_waves
  <script type="text/javascript" src="https://cdn.jsdelivr.net/gh/theme-next/theme-next-three@1/three.min.js"></script>
  <script type="text/javascript" src="https://cdn.jsdelivr.net/gh/theme-next/theme-next-three@latest/three-waves.min.js"></script>
  -->

  <!-- canvas_lines
  <script type="text/javascript" src="https://cdn.jsdelivr.net/gh/theme-next/theme-next-three@1/three.min.js"></script>
  <script type="text/javascript" src="https://cdn.jsdelivr.net/gh/theme-next/theme-next-three@latest/three-waves.min.js"></script>
  -->

  <!-- canvas_sphere
  <script type="text/javascript" src="https://cdn.jsdelivr.net/gh/theme-next/theme-next-three@1/three.min.js"></script>
  <script type="text/javascript" src="https://cdn.jsdelivr.net/gh/theme-next/theme-next-three@latest/three-waves.min.js"></script>
  -->

  <!-- Canvas-nest
  <script type="text/javascript" color="0,0,255" opacity='0.5' zIndex="-2" count="999" src="https://files.cnblogs.com/files/yaohunzhanyue/canvas-nest.js"></script>
  -->

  <!-- Canvas-ribbon -->
  <script type="text/javascript" src="https://cdn.jsdelivr.net/gh/theme-next/theme-next-canvas-ribbon@1/canvas-ribbon.js"></script>
</body>
</html>

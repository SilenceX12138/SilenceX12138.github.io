
    
    
    
    
    [{"authors":null,"categories":null,"content":"I am currently a first-year PhD student in Computer Science at the Cambridge Computer Laboratory, supervised by Prof. Mateja Jamnik. My research interest primarily lies in the explainability of artificial intelligence (XAI), and my current research projects mainly focus on developing interpretable machine learning models for healthcare purposes, especially in the low-sample-size regimes.\nBefore joining Cambridge, I received my BEng in Computer Science and Technology from Beihang University, where I was fortunate to work as a research intern under the supervision of Prof. Si Liu at Cola Laboratory.\nIf you are also passionate about XAI or you would like to discuss anything interesting with me, please feel free to reach out via: silencejiang12138 [at] gmail [dot] com\n","date":1687305600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1687305600,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I am currently a first-year PhD student in Computer Science at the Cambridge Computer Laboratory, supervised by Prof. Mateja Jamnik. My research interest primarily lies in the explainability of artificial intelligence (XAI), and my current research projects mainly focus on developing interpretable machine learning models for healthcare purposes, especially in the low-sample-size regimes.","tags":null,"title":"Xiangjian Jiang","type":"authors"},{"authors":["Xiangjian Jiang","Andrei Margeloiu","Nikola Simidjievski","Mateja Jamnik"],"categories":null,"content":" ","date":1687305600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1687305600,"objectID":"2397e6e107850628816c8ec66151de44","permalink":"https://silencex12138.github.io/publication/jiang2023protogate/","publishdate":"2023-06-21T00:00:00Z","relpermalink":"/publication/jiang2023protogate/","section":"publication","summary":"Tabular biomedical data poses challenges in machine learning because it is often high-dimensional and typically low-sample-size. Previous research has attempted to address these challenges via feature selection approaches, which can lead to unstable performance on real-world data. This suggests that current methods lack appropriate inductive biases that capture patterns common to different samples. In this paper, we propose ProtoGate, a prototype-based neural model that introduces an inductive bias by attending to both homogeneity and heterogeneity across samples. ProtoGate selects features in a global-to-local manner and leverages them to produce explainable predictions via an interpretable prototype-based model. We conduct comprehensive experiments to evaluate the performance of ProtoGate on synthetic and real-world datasets. Our results show that exploiting the homogeneous and heterogeneous patterns in the data can improve prediction accuracy while prototypes imbue interpretability.","tags":[],"title":"ProtoGate: Prototype-based Neural Networks with Local Feature Selection for Tabular Biomedical Data","type":"publication"},{"authors":["Xiangjian Jiang","Xuecheng Nie","Zitian Wang","Luoqi Liu","Si Liu"],"categories":null,"content":" ","date":1664841600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1664841600,"objectID":"67cde3a8a4dcf03144d69d8bad8f8320","permalink":"https://silencex12138.github.io/publication/jiang2022multi/","publishdate":"2022-10-04T00:00:00Z","relpermalink":"/publication/jiang2022multi/","section":"publication","summary":"Existing methods for human mesh recovery mainly focus on single-view frameworks, but they often fail to produce accurate results due to the ill-posed setup. Considering the maturity of the multi-view motion capture system, in this paper, we propose to solve the prior ill-posed problem by leveraging multiple images from different views, thus significantly enhancing the quality of recovered meshes. In particular, we present a novel \\textbf{M}ulti-view human body \\textbf{M}esh \\textbf{T}ranslator (MMT) model for estimating human body mesh with the help of vision transformer. Specifically, MMT takes multi-view images as input and translates them to targeted meshes in a single-forward manner. MMT fuses features of different views in both encoding and decoding phases, leading to representations embedded with global information. Additionally, to ensure the tokens are intensively focused on the human pose and shape, MMT conducts cross-view alignment at the feature level by projecting 3D keypoint positions to each view and enforcing their consistency in geometry constraints. Comprehensive experiments demonstrate that MMT outperforms existing single or multi-view models by a large margin for human mesh recovery task, notably, 28.8\\% improvement in MPVE over the current state-of-the-art method on the challenging HUMBI dataset. Qualitative evaluation also verifies the effectiveness of MMT in reconstructing high-quality human mesh. Codes will be made available upon acceptance.","tags":[],"title":"Multi-view Human Body Mesh Translator","type":"publication"},{"authors":["Bonan Li","Yinhan Hu","Xuecheng Nie","Congying Han","Xiangjian Jiang","Tiande Guo","Luoqi Liu"],"categories":null,"content":" ","date":1659571200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1659571200,"objectID":"fe2a3a6722277900c0a242e0350cb460","permalink":"https://silencex12138.github.io/publication/li2023dropkey/","publishdate":"2022-08-04T00:00:00Z","relpermalink":"/publication/li2023dropkey/","section":"publication","summary":"In this paper, we focus on analyzing and improving the dropout technique for self-attention layers of Vision Transformer, which is important while surprisingly ignored by prior works. In particular, we conduct researches on three core questions. First, what to drop in self-attention layers? Different from dropping attention weights in literature, we propose to move dropout operations forward ahead of attention matrix calculation and set the Key as the dropout unit, yielding a novel dropout-before-softmax scheme. We theoretically verify that this scheme helps keep both regularization and probability features of attention weights, alleviating the overfittings problem to specific patterns and enhancing the model to globally capture vital information; Second, how to schedule the drop ratio in consecutive layers? In contrast to exploit a constant drop ratio for all layers, we present a new decreasing schedule that gradually decreases the drop ratio along the stack of self-attention layers. We experimentally validate the proposed schedule can avoid overfittings in low-level features and missing in high-level semantics, thus improving the robustness and stableness of model training; Third, whether need to perform structured dropout operation as CNN? We attempt patch-based block-version of dropout operation and find that this useful trick for CNN is not essential for ViT. Given exploration on the above three questions, we present the novel DropKey method that regards Key as the drop unit and exploits decreasing schedule for drop ratio, improving ViTs in a general way. Comprehensive experiments demonstrate the effectiveness of DropKey for various ViT architectures, e.g. T2T and VOLO, as well as for various vision tasks, e.g., image classification, object detection, human-object interaction detection and human body shape recovery.","tags":[],"title":"DropKey for Vision Transformer","type":"publication"},{"authors":["Renshuai Tao","Yanlu Wei","Xiangjian Jiang","Hainan Li","Haotong Qin","Jiakai Wang","Yuqing Ma","Libo Zhang","Xianglong Liu"],"categories":null,"content":" ","date":1629676800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1629676800,"objectID":"3862c50d9d76be38c7783138da606a9e","permalink":"https://silencex12138.github.io/publication/tao2021towards/","publishdate":"2021-08-23T00:00:00Z","relpermalink":"/publication/tao2021towards/","section":"publication","summary":"Prohibited items detection in X-ray images often plays an important role in protecting public safety, which often deals with color-monotonous and luster-insufficient objects, resulting in unsatisfactory performance. Till now, there have been rare studies touching this topic due to the lack of specialized high-quality datasets. In this work, we first present a High-quality X-ray (HiXray) security inspection image dataset, which contains 102,928 common prohibited items of 8 categories. It is the largest dataset of high quality for prohibited items detection, gathered from the real-world airport security inspection and annotated by professional security inspectors. Besides, for accurate prohibited item detection, we further propose the Lateral Inhibition Module (LIM) inspired by the fact that humans recognize these items by ignoring irrelevant information and focusing on identifiable characteristics, especially when objects are overlapped with each other. Specifically, LIM, the elaborately designed flexible additional module, suppresses the noisy information flowing maximumly by the Bidirectional Propagation (BP) module and activates the most identifiable charismatic, boundary, from four directions by Boundary Activation (BA) module. We evaluate our method extensively on HiXray and OPIXray and the results demonstrate that it outperforms SOTA detection methods.","tags":[],"title":"Towards real-world X-ray security inspection: A high-quality benchmark and lateral inhibition module for prohibited items detection","type":"publication"}]